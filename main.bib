@inproceedings{Sedlmeier2022Quantifying,
  author       = {Andreas Sedlmeier and Michael Kölle and Robert Müller and Leo Baudrexel and Claudia Linnhoff-Popien},
  title        = {Quantifying Multimodality in World Models},
  booktitle    = {Proceedings of the 14th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2022},
  pages        = {367-374},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0010898500003116},
  isbn         = {978-989-758-547-0}
}

@inproceedings{Koelle2023Improving,
  author       = {Michael Kölle and Alessandro Giovagnoli and Jonas Stein and Maximilian Mansky and Julian Hager and Claudia Linnhoff-Popien},
  title        = {Improving Convergence for Quantum Variational Classifiers Using Weight Re-Mapping},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2023},
  pages        = {251-258},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011696300003393},
  isbn         = {978-989-758-623-1}
}

@inproceedings{Illium2022Constructing,
  author    = {Illium, Steffen and Zorn, Maximilian and Lenta, Cristian and Kölle, Michael and Linnhoff-Popien, Claudia and Gabor, Thomas},
  booktitle = {2022 IEEE Symposium Series on Computational Intelligence (SSCI)},
  title     = {Constructing Organism Networks from Collaborative Self-Replicators},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {1268-1275},
  keywords  = {Neural networks;Collaboration;Computer architecture;Organisms;Task analysis;Computational intelligence;Arithmetic},
  doi       = {10.1109/SSCI51031.2022.10022216}
}

@inproceedings{Illium2023VoronoiPatches,
  author       = {Steffen Illium and Gretchen Griffin and Michael Kölle and Maximilian Zorn and Jonas Nüßlein and Claudia Linnhoff{-}Popien},
  title        = {VoronoiPatches: Evaluating a New Data Augmentation Method},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2023},
  pages        = {350-357},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011670000003393},
  isbn         = {978-989-758-623-1},
  issn         = {2184-433X}
}

@inproceedings{Phan2023AttentionBased,
  author    = {Phan, Thomy and Ritz, Fabian and Nüßlein, Jonas and Kölle, Michael and Gabor, Thomas and Linnhoff-Popien, Claudia},
  title     = {Attention-Based Recurrency for Multi-Agent Reinforcement Learning under State Uncertainty},
  year      = {2023},
  isbn      = {9781450394321},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address   = {Richland, SC},
  abstract  = {State uncertainty poses a major challenge for decentralized coordination. However, state uncertainty is largely neglected in multi-agent reinforcement learning research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this work, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under agent-wise state uncertainty. AERIAL uses a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark. We evaluate AERIAL in a variety of MessySMAC maps, and compare the results with state-based CTDE.},
  booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages     = {2839–2841},
  numpages  = {3},
  keywords  = {dec-pomdp, multi-agent learning, recurrence, state uncertainty},
  location  = {London, United Kingdom},
  series    = {AAMAS '23}
}

@inproceedings{Koelle2023ImprovingPrimate,
  author    = {Michael Kölle and
               Steffen Illium and
               Maximilian Zorn and
               Jonas Nüßlein and
               Patrick Suchostawski and
               Claudia Linnhoff-Popien},
  editor    = {Donatello Conte and
               Ana Fred and
               Oleg Gusikhin and
               Carlo Sansone},
  title     = {Improving Primate Sounds Classification Using Binary Presorting for
               Deep Learning},
  booktitle = {Deep Learning Theory and Applications - 4th International Conference,
               DeLTA 2023, Rome, Italy, July 13-14, 2023, Proceedings},
  series    = {Communications in Computer and Information Science},
  volume    = {1875},
  pages     = {19--34},
  publisher = {Springer},
  year      = {2023},
  url       = {https://doi.org/10.1007/978-3-031-39059-3\_2},
  doi       = {10.1007/978-3-031-39059-3\_2},
  timestamp = {Tue, 13 Aug 2024 14:18:08 +0200},
  isbn      = {978-3-031-39059-3},
  biburl    = {https://dblp.org/rec/conf/delta2/0001IZNSL23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Stein2023Evidence,
  author    = {Stein, Jonas and Chamanian, Farbod and Zorn, Maximilian and Nüßlein, Jonas and Zielinski, Sebastian and Kölle, Michael and Linnhoff-Popien, Claudia},
  title     = {Evidence that PUBO outperforms QUBO when solving continuous optimization problems with the QAOA},
  year      = {2023},
  isbn      = {9798400701207},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3583133.3596358},
  doi       = {10.1145/3583133.3596358},
  abstract  = {Quantum computing provides powerful algorithmic tools that have been shown to outperform established classical solvers in specific optimization tasks. A core step in solving optimization problems with known quantum algorithms such as the Quantum Approximate Optimization Algorithm (QAOA) is the problem formulation. While quantum optimization has historically centered around Quadratic Unconstrained Optimization (QUBO) problems, recent studies show, that many combinatorial problems such as the TSP can be solved more efficiently in their native Polynomial Unconstrained Optimization (PUBO) forms. As many optimization problems in practice also contain continuous variables, our contribution investigates the performance of the QAOA in solving continuous optimization problems when using PUBO and QUBO formulations. Our extensive evaluation on suitable benchmark functions, shows that PUBO formulations generally yield better results, while requiring less qubits. As the multi-qubit interactions needed for the PUBO variant have to be decomposed using the hardware gates available, i.e., currently single- and two-qubit gates, the circuit depth of the PUBO approach outscales its QUBO alternative roughly linearly in the order of the objective function. However, incorporating the planned addition of native multi-qubit gates such as the global M\o{}lmer-S\o{}renson gate, our experiments indicate that PUBO outperforms QUBO for higher order continuous optimization problems in general.},
  booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
  pages     = {2254–2262},
  numpages  = {9},
  keywords  = {quantum computing, continuous optimization, quantum approximate optimization algorithm, quadratic unconstrained binary optimization, polynomial unconstrained binary optimization},
  location  = {Lisbon, Portugal},
  series    = {GECCO '23 Companion}
}

@inproceedings{Koelle2024Weight,
  author    = {Kölle, Michael and Giovagnoli, Alessandro and Stein, Jonas and Mansky, Maximilian Balthasar and Hager, Julian and Rohe, Tobias and Müller, Robert and Linnhoff-Popien, Claudia},
  title     = {Weight Re-mapping for Variational Quantum Algorithms},
  year      = {2024},
  isbn      = {978-3-031-55325-7},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-031-55326-4_14},
  doi       = {10.1007/978-3-031-55326-4_14},
  abstract  = {Inspired by the remarkable success of artificial neural networks across a broad spectrum of AI tasks, variational quantum circuits (VQCs) have recently seen an upsurge in quantum machine learning applications. The promising outcomes shown by VQCs, such as improved generalization and reduced parameter training requirements, are attributed to the robust algorithmic capabilities of quantum computing. However, the current gradient-based training approaches for VQCs do not adequately accommodate the fact that trainable parameters (or weights) are typically used as angles in rotational gates. To address this, we extend the concept of weight re-mapping for VQCs, as introduced by Kölle et al. [9]. This approach unambiguously maps the weights to an interval of length 2π, mirroring data rescaling techniques in conventional machine learning that have proven to be highly beneficial in numerous scenarios. In our study, we employ seven distinct weight re-mapping functions to assess their impact on eight classification datasets, using variational classifiers as a representative example. Our results indicate that weight re-mapping can enhance the convergence speed of the VQC. We assess the efficacy of various re-mapping functions across all datasets and measure their influence on the VQC’s average performance. Our findings indicate that weight re-mapping not only consistently accelerates the convergence of VQCs, regardless of the specific re-mapping function employed, but also significantly increases accuracy in certain cases.},
  booktitle = {Agents and Artificial Intelligence: 15th International Conference, ICAART 2023, Lisbon, Portugal, February 22–24, 2023, Revised Selected Papers},
  pages     = {286–309},
  numpages  = {24},
  keywords  = {Variational quantum circuits, Variational classifier, Weight re-mapping},
  location  = {Lisbon, Portugal}
}

@inproceedings{Koelle2023Learning,
  author       = {Michael Kölle and Tim Matheis and Philipp Altmann and Kyrill Schmid},
  title        = {Learning to Participate Through Trading of Reward Shares},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2023},
  pages        = {355-362},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011781600003393},
  isbn         = {978-989-758-623-1}
}

@inproceedings{Koelle2023Compression,
  author       = {Michael Kölle and Steffen Illium and Carsten Hahn and Lorenz Schauer and Johannes Hutter and Claudia Linnhoff-Popien},
  title        = {Compression of GPS Trajectories Using Autoencoders},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2023},
  pages        = {829-836},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011782100003393},
  isbn         = {978-989-758-623-1}
}

@inproceedings{Phan2023AttentionBasedRecurrence,
  author    = {Phan, Thomy and Ritz, Fabian and Altmann, Philipp and Zorn, Maximilian and Nüßlein, Jonas and Kölle, Michael and Gabor, Thomas and Linnhoff-Popien, Claudia},
  title     = {Attention-based recurrence for multi-agent reinforcement learning under stochastic partial observability},
  year      = {2023},
  publisher = {JMLR.org},
  abstract  = {Stochastic partial observability poses a major challenge for decentralized coordination in multiagent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  articleno = {1157},
  numpages  = {14},
  location  = {Honolulu, Hawaii, USA},
  series    = {ICML'23}
}

@inproceedings{Stein2024Exploring,
  author       = {Jonas Stein and Daniëlle Schuman and Magdalena Benkard and Thomas Holger and Wanja Sajko and Michael Kölle and Jonas Nüßlein and Leo Sünkel and Olivier Salomon and Claudia Linnhoff-Popien},
  title        = {Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines in Fraud Detection},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {177-185},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012326100003636},
  isbn         = {978-989-758-680-4}
}

@article{Phan2024Emergent,
  title    = {Emergent cooperation from mutual acknowledgment exchange in multi-agent reinforcement learning},
  volume   = {38},
  issn     = {1573-7454},
  url      = {https://doi.org/10.1007/s10458-024-09666-5},
  doi      = {10.1007/s10458-024-09666-5},
  abstract = {Peer incentivization (PI) is a recent approach where all agents learn to reward or penalize each other in a distributed fashion, which often leads to emergent cooperation. Current PI mechanisms implicitly assume a flawless communication channel in order to exchange rewards. These rewards are directly incorporated into the learning process without any chance to respond with feedback. Furthermore, most PI approaches rely on global information, which limits scalability and applicability to real-world scenarios where only local information is accessible. In this paper, we propose Mutual Acknowledgment Token Exchange (MATE), a PI approach defined by a two-phase communication protocol to exchange acknowledgment tokens as incentives to shape individual rewards mutually. All agents condition their token transmissions on the locally estimated quality of their own situations based on environmental rewards and received tokens. MATE is completely decentralized and only requires local communication and information. We evaluate MATE in three social dilemma domains. Our results show that MATE is able to achieve and maintain significantly higher levels of cooperation than previous PI approaches. In addition, we evaluate the robustness of MATE in more realistic scenarios, where agents can deviate from the protocol and communication failures can occur. We also evaluate the sensitivity of MATE w.r.t. the choice of token values.},
  number   = {2},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  author   = {Phan, Thomy and Sommer, Felix and Ritz, Fabian and Altmann, Philipp and Nüßlein, Jonas and Kölle, Michael and Belzner, Lenz and Linnhoff-Popien, Claudia},
  month    = jul,
  year     = {2024},
  pages    = {34}
}

@inproceedings{Altmann2024Quantum,
  author    = {Altmann, Philipp and B\"{a}rligea, Adelina and Stein, Jonas and Kölle, Michael and Gabor, Thomas and Phan, Thomy and Linnhof-Popien, Claudia},
  title     = {Quantum Circuit Design: A Reinforcement Learning Challenge},
  year      = {2024},
  isbn      = {9798400704864},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address   = {Richland, SC},
  abstract  = {To assess the prospects of using reinforcement learning (RL) for selecting and parameterizing quantum gates to build viable circuit architectures, we introduce the quantum circuit designer (QCD). By considering quantum control a decision-making problem, we strive to profit from advanced RL exploration mechanisms to overcome the need for granular specification and hand-crafted architectures. To evaluate current state-of-the-art RL algorithms, we define generic objectives that arise from quantum architecture search and circuit optimization. Those evaluation results reveal challenges inherent to learning optimal quantum control.},
  booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  pages     = {2123–2125},
  numpages  = {3},
  keywords  = {architecture search, circuit optimization, quantum computing, reinforcement learning},
  location  = {Auckland, New Zealand},
  series    = {AAMAS '24}
}

@inproceedings{Koelle2024Aquarium,
  author       = {Michael Kölle and Yannick Erpelding and Fabian Ritz and Thomy Phan and Steffen Illium and Claudia Linnhoff-Popien},
  title        = {Aquarium: A Comprehensive Framework for Exploring Predator-Prey Dynamics Through Multi-Agent Reinforcement Learning Algorithms},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {59-70},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012382300003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Koelle2024MultiAgent,
  author       = {Michael Kölle and Felix Topp and Thomy Phan and Philipp Altmann and Jonas Nüßlein and Claudia Linnhoff-Popien},
  title        = {Multi-Agent Quantum Reinforcement Learning Using Evolutionary Optimization},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {71-82},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012382800003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Koelle2024Reinforcement,
  author       = {Michael Kölle and Tom Schubert and Philipp Altmann and Maximilian Zorn and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {A Reinforcement Learning Environment for Directed Quantum Circuit Synthesis},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {83-94},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012383200003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Stein2024Improving,
  author       = {Jonas Stein and Navid Roshani and Maximilian Zorn and Philipp Altmann and Michael Kölle and Claudia Linnhoff-Popien},
  title        = {Improving Parameter Training for VQEs by Sequential Hamiltonian Assembly},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {99-109},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012312500003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Koelle2024QuantumAdvantage,
  author       = {Michael Kölle and Mohamad Hgog and Fabian Ritz and Philipp Altmann and Maximilian Zorn and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {Quantum Advantage Actor-Critic for Reinforcement Learning},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {297-304},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012383900003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Mueller2024ClusterComm,
  author       = {Robert Müller and Hasan Turalic and Thomy Phan and Michael Kölle and Jonas Nüßlein and Claudia Linnhoff-Popien},
  title        = {ClusterComm: Discrete Communication in Decentralized MARL Using Internal Representation Clustering},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {305-312},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012384300003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Koelle2024Towards,
  author       = {Michael Kölle and Afrae Ahouzi and Pascal Debus and Robert Müller and Daniëlle Schuman and Claudia Linnhoff-Popien},
  title        = {Towards Efficient Quantum Anomaly Detection: One-Class SVMs Using Variable Subsampling and Randomized Measurements},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {324-335},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012381200003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Stein2024Benchmarking,
  author       = {Jonas Stein and Michael Poppel and Philip Adamczyk and Ramona Fabry and Zixin Wu and Michael Kölle and Jonas Nüßlein and Daniëlle Schuman and Philipp Altmann and Thomas Ehmer and Vijay Narasimhan and Claudia Linnhoff-Popien},
  title        = {Benchmarking Quantum Surrogate Models on Scarce and Noisy Data},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {352-359},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012348900003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Koelle2024Disentangling,
  author       = {Michael Kölle and Jonas Maurer and Philipp Altmann and Leo Sünkel and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {Disentangling Quantum and Classical Contributions in Hybrid Quantum Machine Learning Architectures},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {649-656},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012381600003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Suenkel2024Quantum,
  author       = {Leo Sünkel and Philipp Altmann and Michael Kölle and Thomas Gabor},
  title        = {Quantum Federated Learning for Image Classification},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {936-942},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012421200003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Stein2024Introducing,
  author       = {Jonas Stein and Tobias Rohe and Francesco Nappi and Julian Hager and David Bucher and Maximilian Zorn and Michael Kölle and Claudia Linnhoff-Popien},
  title        = {Introducing Reduced-Width QNNs, an AI-Inspired Ansatz Design Pattern},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {1127-1134},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012449800003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Suenkel2024Towards,
  author    = {Sünkel, Leo
               and Kölle, Michael
               and Rohe, Tobias
               and Gabor, Thomas},
  editor    = {Steffen, Bernhard},
  title     = {Towards Federated Learning on the Quantum Internet},
  booktitle = {Computational Science – ICCS 2024: 24th International Conference, Malaga, Spain, July 2–4, 2024, Proceedings, Part VI},
  year      = {2024},
  isbn      = {978-3-031-63777-3},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-031-63778-0_24},
  doi       = {10.1007/978-3-031-63778-0_24},
  abstract  = {While the majority of focus in quantum computing has so far been on monolithic quantum systems, quantum communication networks and the quantum internet in particular are increasingly receiving attention from researchers and industry alike. The quantum internet may allow a plethora of applications such as distributed or blind quantum computing, though research still is at an early stage, both for its physical implementation as well as algorithms; thus suitable applications are an open research question. We evaluate a potential application for the quantum internet, namely quantum federated learning. We run experiments under different settings in various scenarios (e.g. network constraints) using several datasets from different domains and show that (1) quantum federated learning is a valid alternative for regular training and (2) network topology and nature of training are crucial considerations as they may drastically influence the models performance. The results indicate that more comprehensive research is required to optimally deploy quantum federated learning on a potential quantum internet.},
  pages     = {330–344},
  numpages  = {15},
  keywords  = {Quantum Federated Learning, Quantum Internet, Quantum Machine Learning, Quantum Communication Networks},
  location  = {Malaga, Spain}
}

@inproceedings{Koelle2024QuantumDenoising,
  author    = { Kölle, Michael and Stenzel, Gerhard and Stein, Jonas and Zielinski, Sebastian and Ommer, Bjorn and Linnhoff-Popien, Claudia },
  booktitle = { 2024 IEEE International Conference on Quantum Software (QSW) },
  title     = { Quantum Denoising Diffusion Models },
  year      = {2024},
  volume    = {},
  issn      = {},
  pages     = {88-98},
  abstract  = { In recent years, machine learning models like DALL-E, Craiyon, and Stable Diffusion have gained significant attention for their ability to generate high-resolution images from concise descriptions. Concurrently, quantum computing is showing promising advances, especially with quantum machine learning which capitalizes on quantum mechanics to meet the increasing computational requirements of traditional machine learning algorithms. This paper explores the integration of quantum machine learning and variational quantum circuits to augment the efficacy of diffusion-based image generation models. Specifically, we address two challenges of classical diffusion models: their low sampling speed and the extensive parameter requirements. We introduce two quantum diffusion models and benchmark their capabilities against their classical counterparts using MNIST digits, Fashion MNIST, and CIFAR-10. Our models surpass the classical models with similar parameter counts in terms of performance metrics FID, SSIM, and PSNR. Moreover, we introduce a consistency model unitary single sampling architecture that combines the diffusion procedure into a single step, enabling a fast one-step image generation. },
  keywords  = {Measurement;Image synthesis;Computational modeling;Noise reduction;Computer architecture;Benchmark testing;Diffusion models},
  doi       = {10.1109/QSW62656.2024.00023},
  url       = {https://doi.ieeecomputersociety.org/10.1109/QSW62656.2024.00023},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = Jul
}

@inproceedings{Koelle2024Study,
  author    = { Kölle, Michael and Witter, Timo and Rohe, Tobias and Stenzel, Gerhard and Altmann, Philipp and Gabor, Thomas },
  booktitle = { 2024 IEEE International Conference on Quantum Software (QSW) },
  title     = { A Study on Optimization Techniques for Variational Quantum Circuits in Reinforcement Learning },
  year      = {2024},
  volume    = {},
  issn      = {},
  pages     = {157-167},
  abstract  = { Quantum Computing aims to streamline machine learning, making it more effective with fewer trainable parameters. This reduction of parameters can speed up the learning process and reduce the use of computational resources. However, in the current phase of quantum computing development, known as the noisy intermediate-scale quantum era (NISQ), learning is difficult due to a limited number of qubits and widespread quantum noise. To overcome these challenges, researchers are focusing on variational quantum circuits (VQCs). VQCs are hybrid algorithms that merge a quantum circuit, which can be adjusted through parameters, with traditional classical optimization techniques. These circuits require only few qubits for effective learning. Recent studies have presented new ways of applying VQCs to reinforcement learning, showing promising results that warrant further exploration. This study investigates the effects of various techniques — data re-uploading, input scaling, output scaling — and introduces exponential learning rate decay in the quantum proximal policy optimization algorithm’s actor-VQC. We assess these methods in the popular Frozen Lake and Cart Pole environments. Our focus is on their ability to reduce the number of parameters in the VQC without losing effectiveness. Our findings indicate that data re-uploading and an exponential learning rate decay significantly enhance hyperparameter stability and overall performance. While input scaling does not improve parameter efficiency, output scaling effectively manages greediness, leading to increased learning speed and robustness. },
  keywords  = {Qubit;Noise;Reinforcement learning;Software;Robustness;Circuit stability;Time factors},
  doi       = {10.1109/QSW62656.2024.00031},
  url       = {https://doi.ieeecomputersociety.org/10.1109/QSW62656.2024.00031},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = Jul
}

@inproceedings{Stenzel2025SEGym,
  author    = {Stenzel, Gerhard
               and Schmid, Kyrill
               and Kölle, Michael
               and Altmann, Philipp
               and Lingsch-Rosenfeld, Marian
               and Zorn, Maximilian
               and Bücher, Tim
               and Gabor, Thomas
               and Wirsing, Martin
               and Belzner, Lenz},
  editor    = {Steffen, Bernhard},
  title     = {SEGym: Optimizing Large Language Model Assisted Software Engineering Agents with Reinforcement Learning},
  booktitle = {Bridging the Gap Between AI and Reality},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {107--124},
  abstract  = {Current software development agents based on large language models (LLMs) are often defined using heuristic methods, which can limit their flexibility and effectiveness. Moreover, the entry barriers for new researchers in this field are high, largely due to the complex infrastructure required to develop and optimize these agents. This paper proposes a new approach: modeling software development agents over LLMs as a partially observable Markov decision process (POMDP) to enable data-driven optimization. To support this approach, we introduce SEGym, a framework based on the Gym interface for reinforcement learning agents. SEGym simplifies the setup of optimization experiments for software development agents within the POMDP framework, making it more accessible for researchers to engage in this field.},
  isbn      = {978-3-031-75434-0}
}

@inproceedings{Koelle2024Optimizing,
  author    = { Kölle, Michael and Seidl, Daniel and Zorn, Maximilian and Altmann, Philipp and Stein, Jonas and Gabor, Thomas },
  booktitle = { 2024 IEEE International Conference on Quantum Computing and Engineering (QCE) },
  title     = {{ Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning }},
  year      = {2024},
  volume    = {},
  issn      = {},
  pages     = {323-328},
  abstract  = { Quantum Reinforcement Learning (QRL) offers potential advantages over classical Reinforcement Learning, such as compact state space representation and faster convergence in certain scenarios. However, practical benefits require further validation. QRL faces challenges like flat solution landscapes, where traditional gradient-based methods are inefficient, necessitating the use of gradient-free algorithms. This work explores the integration of metaheuristic algorithms — Particle Swarm Optimization, Ant Colony Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony Search — into QRL. These algorithms provide flexibility and efficiency in parameter optimization. Evaluations in $5\times 5$ MiniGrid Reinforcement Learning environments show that, all algorithms yield nearoptimal results, with Simulated Annealing and Particle Swarm Optimization performing best. In the Cart Pole environment, Simulated Annealing, Genetic Algorithms, and Particle Swarm Optimization achieve optimal results, while the others perform slightly better than random action selection. These findings demonstrate the potential of Particle Swarm Optimization and Simulated Annealing for efficient QRL learning, emphasizing the need for careful algorithm selection and adaptation. },
  keywords  = {Metaheuristics;Stability criteria;Reinforcement learning;Simulated annealing;Circuit stability;Particle swarm optimization;Quantum circuit;Robots;Genetic algorithms;Testing},
  doi       = {10.1109/QCE60285.2024.10300},
  url       = {https://doi.ieeecomputersociety.org/10.1109/QCE60285.2024.10300},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = sep
}

@inproceedings{Stenzel2024SelfReplicating,
  author   = {Stenzel, Gerhard and Zorn, Maximilian and Altmann, Philipp and Mansky, Maximilian Balthasar and Kölle, Michael and Gabor, Thomas},
  title    = {Self-Replicating Prompts for Large Language Models: Towards Artificial Culture},
  volume   = {ALIFE 2024: Proceedings of the 2024 Artificial Life Conference},
  series   = {Artificial Life Conference Proceedings},
  pages    = {110},
  year     = {2024},
  month    = {07},
  abstract = {We consider various setups where large language models (LLMs) communicate solely with themselves or other LLMs. In accordance with similar results known for program representations (like λ-expressions or automata), we observe a natural tendency for the evolution of self-replicating text pieces, i.e., LLM prompts that cause any receiving LLM to produce a response similar to the original prompt. We argue that the study of these self-replicating patterns, which exist in natural language and across different types of LLMs, may have important implications on artificial intelligence, cultural studies, and related fields.},
  doi      = {10.1162/isal_a_00813},
  url      = {https://doi.org/10.1162/isal\_a\_00813},
  eprint   = {https://direct.mit.edu/isal/proceedings-pdf/isal2024/36/110/2461211/isal\_a\_00813.pdf}
}

@inproceedings{Zorn2024SelfAdaptive,
  author   = {Zorn, Maximilian and Altmann, Philipp and Stenzel, Gerhard and Kölle, Michael and Linnhoff-Popien, Claudia and Gabor, Thomas},
  title    = {Self-Adaptive Robustness of Applied Neural-Network-Soups},
  volume   = {ALIFE 2024: Proceedings of the 2024 Artificial Life Conference},
  series   = {Artificial Life Conference Proceedings},
  pages    = {74},
  year     = {2024},
  month    = {07},
  abstract = {We consider the dynamics of artificial chemistry systems consisting of small, interacting neural-network particles. Although recent explorations into properties of such systems have shown interesting phenomena, like self-replication tendencies, social interplay, and the ability for multi-objective applications, most of these settings are reasoned about in the abstract weight space. We extend this setup to involve an applied, stateful positioning task with mutual dependencies and show that stable configurations can be found jointly in both the weight space and 3D space. We show that the main contributing factor is enabling the networks to self-adapt their interaction rates depending on their internal stability or their ability to position themselves correctly. We find that this method effectively prepares the network assembly against potentially destabilizing interactions, promoting emergent stability while preventing convergence to trivial states.},
  doi      = {10.1162/isal_a_00811},
  url      = {https://doi.org/10.1162/isal\_a\_00811},
  eprint   = {https://direct.mit.edu/isal/proceedings-pdf/isal2024/36/74/2461231/isal\_a\_00811.pdf}
}

@inproceedings{Zielinski2024Max3SAT,
  author    = {Zielinski, Sebastian and Nüßlein, Jonas and Kölle, Michael and Gabor, Thomas and Linnhoff-Popien, Claudia and Feld, Sebastian},
  booktitle = {2024 IEEE International Conference on Quantum Computing and Engineering (QCE)},
  title     = {Solving Max-3SAT Using QUBO Approximation},
  year      = {2024},
  volume    = {01},
  number    = {},
  pages     = {681-691},
  keywords  = {Computers;Performance evaluation;Annealing;Systematics;Qubit;Quantum annealing;Hardware;Error correction;Approximation methods;Optimization;Quadratic Unconstrained Binary Optimization;Combinatorial Optimization;Max-3SAT;Approximation},
  doi       = {10.1109/QCE60285.2024.00085}
}

@inproceedings{Zorn2024Cohesive,
  author    = {Zorn, Maximilian and Stein, Jonas and Altmann, Philipp and Kölle, Michael and Linnhoff-Popien, Claudia and Gabor, Thomas},
  booktitle = {2024 IEEE International Conference on Quantum Computing and Engineering (QCE)},
  title     = {Cohesive Quantum Circuit Layer Construction with Reinforcement Learning},
  year      = {2024},
  volume    = {01},
  number    = {},
  pages     = {1721-1730},
  keywords  = {Training;Measurement;Qubit;Reinforcement learning;Logic gates;Linear programming;Search problems;Iterative methods;Quantum circuit;Integrated circuit modeling;Reinforcement Learning;Quantum Computing;Circuit Optimization;Quantum Circuit Construction},
  doi       = {10.1109/QCE60285.2024.00201}
}

@article{Altmann2024Discriminative,
  title    = {Discriminative reward co-training},
  issn     = {1433-3058},
  url      = {https://doi.org/10.1007/s00521-024-10512-8},
  doi      = {10.1007/s00521-024-10512-8},
  abstract = {We propose discriminative reward co-training (DIRECT) as an extension to deep reinforcement learning algorithms. Building upon the concept of self-imitation learning (SIL), we introduce an imitation buffer to store beneficial trajectories generated by the policy, determined by their return. A discriminator network is trained concurrently to the policy to distinguish between trajectories generated by the current policy and beneficial trajectories generated by previous policies. The discriminator’s verdict is used to construct a reward signal for optimizing the policy. By interpolating prior experience, DIRECT is able to act as a reward surrogate, steering policy optimization toward more valuable regions of the reward landscape, thus, toward learning an optimal policy. In this article, we formally introduce the additional components, their intended purpose and parameterization, and define a unified training procedure. To reveal insights into the mechanics of the proposed architecture, we provide evaluations of the introduced hyperparameters. Further benchmark evaluations in various discrete and continuous control environments provide evidence that DIRECT is especially beneficial in environments possessing sparse rewards, hard exploration tasks, and shifting circumstances. Our results show that DIRECT outperforms state-of-the-art algorithms in those challenging scenarios by providing a surrogate reward to the policy and direct the optimization toward valuable areas.},
  journal  = {Neural Computing and Applications},
  author   = {Altmann, Philipp and Ritz, Fabian and Zorn, Maximilian and Kölle, Michael and Phan, Thomy and Gabor, Thomas and Linnhoff-Popien, Claudia},
  month    = dec,
  year     = {2024}
}








@misc{Rohe2024Pipeline,
  title         = {From Problem to Solution: A general Pipeline to Solve Optimisation Problems on Quantum Hardware},
  author        = {Tobias Rohe and Simon Grätz and Michael Kölle and Sebastian Zielinski and Jonas Stein and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2406.19876},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph},
  url           = {https://arxiv.org/abs/2406.19876},
  keywords      = {insubmission}
}

@misc{Koelle2022Decentralized,
  title         = {Decentralized scheduling through an adaptive, trading-based multi-agent system},
  author        = {Michael Kölle and Lennart Rietdorf and Kyrill Schmid},
  year          = {2022},
  eprint        = {2207.11172},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2207.11172},
  keywords      = {insubmission}
}

@misc{Koelle2024Architectural,
  title         = {Architectural Influence on Variational Quantum Circuits in Multi-Agent Reinforcement Learning: Evolutionary Strategies for Optimization},
  author        = {Michael Kölle and Karola Schneider and Sabrina Egger and Felix Topp and Thomy Phan and Philipp Altmann and Jonas Nüßlein and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2407.20739},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph},
  url           = {https://arxiv.org/abs/2407.20739},
  keywords      = {insubmission}
}

@misc{Koelle2024Efficient,
  title         = {Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling},
  author        = {Michael Kölle and Afrae Ahouzi and Pascal Debus and Elif Çetiner and Robert Müller and Daniëlle Schuman and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2407.20753},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2407.20753},
  keywords      = {insubmission}
}

@misc{Altmann2024Challenges,
  title         = {Challenges for Reinforcement Learning in Quantum Circuit Design},
  author        = {Philipp Altmann and Jonas Stein and Michael Kölle and Adelina Bärligea and Thomas Gabor and Thomy Phan and Sebastian Feld and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2312.11337},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph},
  url           = {https://arxiv.org/abs/2312.11337},
  keywords      = {insubmission}
}

@misc{Rohe2024Coconut,
  title         = {Coconut Palm Tree Counting on Drone Images with Deep Object Detection and Synthetic Training Data},
  author        = {Tobias Rohe and Barbara Böhm and Michael Kölle and Jonas Stein and Robert Müller and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2412.11949},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/2412.11949},
  keywords      = {insubmission}
}

@misc{Koelle2025PIMAEX,
  title         = {PIMAEX: Multi-Agent Exploration through Peer Incentivization},
  author        = {Michael Kölle and Johannes Tochtermann and Julian Schönberger and Gerhard Stenzel and Philipp Altmann and Claudia Linnhoff-Popien},
  year          = {2025},
  eprint        = {2501.01266},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2501.01266},
  keywords      = {insubmission}
}

@misc{Rohe2025Optimization,
  title         = {Optimization of Link Configuration for Satellite Communication Using Reinforcement Learning},
  author        = {Tobias Rohe and Michael Kölle and Jan Matheis and Rüdiger Höpfl and Leo Sünkel and Claudia Linnhoff-Popien},
  year          = {2025},
  eprint        = {2501.08220},
  archiveprefix = {arXiv},
  primaryclass  = {cs.AI},
  url           = {https://arxiv.org/abs/2501.08220},
  keywords      = {insubmission}
}

@misc{Rohe2025Investigating,
  title         = {Investigating Parameter-Efficiency of Hybrid QuGANs Based on Geometric Properties of Generated Sea Route Graphs},
  author        = {Tobias Rohe and Florian Burger and Michael Kölle and Sebastian Wölckert and Maximilian Zorn and Claudia Linnhoff-Popien},
  year          = {2025},
  eprint        = {2501.08678},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/2501.08678},
  keywords      = {insubmission}
}

@misc{Altmann2024MEDIATE,
  title         = {MEDIATE: Mutually Endorsed Distributed Incentive Acknowledgment Token Exchange},
  author        = {Philipp Altmann and Katharina Winter and Michael Kölle and Maximilian Zorn and Thomy Phan and Claudia Linnhoff-Popien},
  year          = {2024},
  eprint        = {2404.03431},
  archiveprefix = {arXiv},
  primaryclass  = {cs.MA},
  url           = {https://arxiv.org/abs/2404.03431},
  keywords      = {insubmission}
}

@misc{Stenzel2024Qandle,
  title         = {Qandle: Accelerating State Vector Simulation Using Gate-Matrix Caching and Circuit Splitting},
  author        = {Gerhard Stenzel and Sebastian Zielinski and Michael Kölle and Philipp Altmann and Jonas Nüßlein and Thomas Gabor},
  year          = {2024},
  eprint        = {2404.09213},
  archiveprefix = {arXiv},
  primaryclass  = {quant-ph},
  url           = {https://arxiv.org/abs/2404.09213},
  keywords      = {insubmission}
}

@misc{Koelle2024QuantumTransfer,
  title    = {Quantum Transfer Learning: The Impact of Classical Preprocessing},
  author   = {Michael Kölle and Jonas Maurer and Philipp Altmann and Leo Sünkeland Jonas Stein and Julian Hager and Sebastian Zielinski and Claudia Linnhoff-Popien},
  year     = {2024},
  keywords = {insubmission}
}