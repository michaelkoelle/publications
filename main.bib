@conference{Sedlmeier2022Quantifying,
  author       = {Andreas Sedlmeier and Michael Kölle and Robert Müller and Leo Baudrexel and Claudia Linnhoff-Popien},
  title        = {Quantifying Multimodality in World Models},
  booktitle    = {Proceedings of the 14th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART,},
  year         = {2022},
  pages        = {367-374},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0010898500003116},
  isbn         = {978-989-758-547-0}
}

@conference{Koelle2023Improving,
  author       = {Michael Kölle and Alessandro Giovagnoli and Jonas Stein and Maximilian Mansky and Julian Hager and Claudia Linnhoff-Popien},
  title        = {Improving Convergence for Quantum Variational Classifiers Using Weight Re-Mapping},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART,},
  year         = {2023},
  pages        = {251-258},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011696300003393},
  isbn         = {978-989-758-623-1}
}

@inproceedings{Illium2022Constructing,
  author    = {Illium, Steffen and Zorn, Maximilian and Lenta, Cristian and Kölle, Michael and Linnhoff-Popien, Claudia and Gabor, Thomas},
  booktitle = {2022 IEEE Symposium Series on Computational Intelligence (SSCI)},
  title     = {Constructing Organism Networks from Collaborative Self-Replicators},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {1268-1275},
  keywords  = {Neural networks;Collaboration;Computer architecture;Organisms;Task analysis;Computational intelligence;Arithmetic},
  doi       = {10.1109/SSCI51031.2022.10022216}
}

@conference{Illium2023VoronoiPatches,
  author       = {Steffen Illium and Gretchen Griffin and Michael Kölle and Maximilian Zorn and Jonas Nüßlein and Claudia Linnhoff{-}Popien},
  title        = {VoronoiPatches: Evaluating a New Data Augmentation Method},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2023},
  pages        = {350-357},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011670000003393},
  isbn         = {978-989-758-623-1},
  issn         = {2184-433X}
}

@inproceedings{Phan2023AttentionBased,
  author    = {Phan, Thomy and Ritz, Fabian and N\"{u}\ss{}lein, Jonas and K\"{o}lle, Michael and Gabor, Thomas and Linnhoff-Popien, Claudia},
  title     = {Attention-Based Recurrency for Multi-Agent Reinforcement Learning under State Uncertainty},
  year      = {2023},
  isbn      = {9781450394321},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address   = {Richland, SC},
  abstract  = {State uncertainty poses a major challenge for decentralized coordination. However, state uncertainty is largely neglected in multi-agent reinforcement learning research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this work, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under agent-wise state uncertainty. AERIAL uses a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark. We evaluate AERIAL in a variety of MessySMAC maps, and compare the results with state-based CTDE.},
  booktitle = {Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems},
  pages     = {2839–2841},
  numpages  = {3},
  keywords  = {dec-pomdp, multi-agent learning, recurrence, state uncertainty},
  location  = {London, United Kingdom},
  series    = {AAMAS '23}
}

@inproceedings{Koelle2023ImprovingPrimate,
  author    = {Michael K{\"{o}}lle and
               Steffen Illium and
               Maximilian Zorn and
               Jonas N{\"{u}}{\ss}lein and
               Patrick Suchostawski and
               Claudia Linnhoff{-}Popien},
  editor    = {Donatello Conte and
               Ana Fred and
               Oleg Gusikhin and
               Carlo Sansone},
  title     = {Improving Primate Sounds Classification Using Binary Presorting for
               Deep Learning},
  booktitle = {Deep Learning Theory and Applications - 4th International Conference,
               DeLTA 2023, Rome, Italy, July 13-14, 2023, Proceedings},
  series    = {Communications in Computer and Information Science},
  volume    = {1875},
  pages     = {19--34},
  publisher = {Springer},
  year      = {2023},
  url       = {https://doi.org/10.1007/978-3-031-39059-3\_2},
  doi       = {10.1007/978-3-031-39059-3\_2},
  timestamp = {Tue, 13 Aug 2024 14:18:08 +0200},
  isbn      = {978-3-031-39059-3},
  biburl    = {https://dblp.org/rec/conf/delta2/0001IZNSL23.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Stein2023Evidence,
  author    = {Stein, Jonas and Chamanian, Farbod and Zorn, Maximilian and N\"{u}\ss{}lein, Jonas and Zielinski, Sebastian and K\"{o}lle, Michael and Linnhoff-Popien, Claudia},
  title     = {Evidence that PUBO outperforms QUBO when solving continuous optimization problems with the QAOA},
  year      = {2023},
  isbn      = {9798400701207},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3583133.3596358},
  doi       = {10.1145/3583133.3596358},
  abstract  = {Quantum computing provides powerful algorithmic tools that have been shown to outperform established classical solvers in specific optimization tasks. A core step in solving optimization problems with known quantum algorithms such as the Quantum Approximate Optimization Algorithm (QAOA) is the problem formulation. While quantum optimization has historically centered around Quadratic Unconstrained Optimization (QUBO) problems, recent studies show, that many combinatorial problems such as the TSP can be solved more efficiently in their native Polynomial Unconstrained Optimization (PUBO) forms. As many optimization problems in practice also contain continuous variables, our contribution investigates the performance of the QAOA in solving continuous optimization problems when using PUBO and QUBO formulations. Our extensive evaluation on suitable benchmark functions, shows that PUBO formulations generally yield better results, while requiring less qubits. As the multi-qubit interactions needed for the PUBO variant have to be decomposed using the hardware gates available, i.e., currently single- and two-qubit gates, the circuit depth of the PUBO approach outscales its QUBO alternative roughly linearly in the order of the objective function. However, incorporating the planned addition of native multi-qubit gates such as the global M\o{}lmer-S\o{}renson gate, our experiments indicate that PUBO outperforms QUBO for higher order continuous optimization problems in general.},
  booktitle = {Proceedings of the Companion Conference on Genetic and Evolutionary Computation},
  pages     = {2254–2262},
  numpages  = {9},
  keywords  = {quantum computing, continuous optimization, quantum approximate optimization algorithm, quadratic unconstrained binary optimization, polynomial unconstrained binary optimization},
  location  = {Lisbon, Portugal},
  series    = {GECCO '23 Companion}
}

@inproceedings{Koelle2024Weight,
  author    = {K\"{o}lle, Michael and Giovagnoli, Alessandro and Stein, Jonas and Mansky, Maximilian Balthasar and Hager, Julian and Rohe, Tobias and M\"{u}ller, Robert and Linnhoff-Popien, Claudia},
  title     = {Weight Re-mapping for Variational Quantum Algorithms},
  year      = {2024},
  isbn      = {978-3-031-55325-7},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-031-55326-4_14},
  doi       = {10.1007/978-3-031-55326-4_14},
  abstract  = {Inspired by the remarkable success of artificial neural networks across a broad spectrum of AI tasks, variational quantum circuits (VQCs) have recently seen an upsurge in quantum machine learning applications. The promising outcomes shown by VQCs, such as improved generalization and reduced parameter training requirements, are attributed to the robust algorithmic capabilities of quantum computing. However, the current gradient-based training approaches for VQCs do not adequately accommodate the fact that trainable parameters (or weights) are typically used as angles in rotational gates. To address this, we extend the concept of weight re-mapping for VQCs, as introduced by K\"{o}lle et al. [9]. This approach unambiguously maps the weights to an interval of length 2π, mirroring data rescaling techniques in conventional machine learning that have proven to be highly beneficial in numerous scenarios. In our study, we employ seven distinct weight re-mapping functions to assess their impact on eight classification datasets, using variational classifiers as a representative example. Our results indicate that weight re-mapping can enhance the convergence speed of the VQC. We assess the efficacy of various re-mapping functions across all datasets and measure their influence on the VQC’s average performance. Our findings indicate that weight re-mapping not only consistently accelerates the convergence of VQCs, regardless of the specific re-mapping function employed, but also significantly increases accuracy in certain cases.},
  booktitle = {Agents and Artificial Intelligence: 15th International Conference, ICAART 2023, Lisbon, Portugal, February 22–24, 2023, Revised Selected Papers},
  pages     = {286–309},
  numpages  = {24},
  keywords  = {Variational quantum circuits, Variational classifier, Weight re-mapping},
  location  = {Lisbon, Portugal}
}

@conference{Koelle2023Learning,
  author       = {Michael Kölle and Tim Matheis and Philipp Altmann and Kyrill Schmid},
  title        = {Learning to Participate Through Trading of Reward Shares},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART,},
  year         = {2023},
  pages        = {355-362},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011781600003393},
  isbn         = {978-989-758-623-1}
}

@conference{Koelle2023Compression,
  author       = {Michael Kölle and Steffen Illium and Carsten Hahn and Lorenz Schauer and Johannes Hutter and Claudia Linnhoff-Popien},
  title        = {Compression of GPS Trajectories Using Autoencoders},
  booktitle    = {Proceedings of the 15th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART,},
  year         = {2023},
  pages        = {829-836},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0011782100003393},
  isbn         = {978-989-758-623-1}
}

@inproceedings{Phan2023AttentionBasedRecurrence,
  author    = {Phan, Thomy and Ritz, Fabian and Altmann, Philipp and Zorn, Maximilian and N\"{u}\ss{}lein, Jonas and K\"{o}lle, Michael and Gabor, Thomas and Linnhoff-Popien, Claudia},
  title     = {Attention-based recurrence for multi-agent reinforcement learning under stochastic partial observability},
  year      = {2023},
  publisher = {JMLR.org},
  abstract  = {Stochastic partial observability poses a major challenge for decentralized coordination in multiagent reinforcement learning but is largely neglected in state-of-the-art research due to a strong focus on state-based centralized training for decentralized execution (CTDE) and benchmarks that lack sufficient stochasticity like StarCraft Multi-Agent Challenge (SMAC). In this paper, we propose Attention-based Embeddings of Recurrence In multi-Agent Learning (AERIAL) to approximate value functions under stochastic partial observability. AERIAL replaces the true state with a learned representation of multi-agent recurrence, considering more accurate information about decentralized agent decisions than state-based CTDE. We then introduce MessySMAC, a modified version of SMAC with stochastic observations and higher variance in initial states, to provide a more general and configurable benchmark regarding stochastic partial observability. We evaluate AERIAL in Dec-Tiger as well as in a variety of SMAC and MessySMAC maps, and compare the results with state-based CTDE. Furthermore, we evaluate the robustness of AERIAL and state-based CTDE against various stochasticity configurations in MessySMAC.},
  booktitle = {Proceedings of the 40th International Conference on Machine Learning},
  articleno = {1157},
  numpages  = {14},
  location  = {Honolulu, Hawaii, USA},
  series    = {ICML'23}
}

@conference{Stein2024Exploring,
  author       = {Jonas Stein and Daniëlle Schuman and Magdalena Benkard and Thomas Holger and Wanja Sajko and Michael Kölle and Jonas Nüßlein and Leo Sünkel and Olivier Salomon and Claudia Linnhoff-Popien},
  title        = {Exploring Unsupervised Anomaly Detection with Quantum Boltzmann Machines in Fraud Detection},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {177-185},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012326100003636},
  isbn         = {978-989-758-680-4}
}

@article{Phan2024Emergent,
  title    = {Emergent cooperation from mutual acknowledgment exchange in multi-agent reinforcement learning},
  volume   = {38},
  issn     = {1573-7454},
  url      = {https://doi.org/10.1007/s10458-024-09666-5},
  doi      = {10.1007/s10458-024-09666-5},
  abstract = {Peer incentivization (PI) is a recent approach where all agents learn to reward or penalize each other in a distributed fashion, which often leads to emergent cooperation. Current PI mechanisms implicitly assume a flawless communication channel in order to exchange rewards. These rewards are directly incorporated into the learning process without any chance to respond with feedback. Furthermore, most PI approaches rely on global information, which limits scalability and applicability to real-world scenarios where only local information is accessible. In this paper, we propose Mutual Acknowledgment Token Exchange (MATE), a PI approach defined by a two-phase communication protocol to exchange acknowledgment tokens as incentives to shape individual rewards mutually. All agents condition their token transmissions on the locally estimated quality of their own situations based on environmental rewards and received tokens. MATE is completely decentralized and only requires local communication and information. We evaluate MATE in three social dilemma domains. Our results show that MATE is able to achieve and maintain significantly higher levels of cooperation than previous PI approaches. In addition, we evaluate the robustness of MATE in more realistic scenarios, where agents can deviate from the protocol and communication failures can occur. We also evaluate the sensitivity of MATE w.r.t. the choice of token values.},
  number   = {2},
  journal  = {Autonomous Agents and Multi-Agent Systems},
  author   = {Phan, Thomy and Sommer, Felix and Ritz, Fabian and Altmann, Philipp and Nüßlein, Jonas and Kölle, Michael and Belzner, Lenz and Linnhoff-Popien, Claudia},
  month    = jul,
  year     = {2024},
  pages    = {34}
}

@inproceedings{Altmann2024Quantum,
  author    = {Altmann, Philipp and B\"{a}rligea, Adelina and Stein, Jonas and K\"{o}lle, Michael and Gabor, Thomas and Phan, Thomy and Linnhof-Popien, Claudia},
  title     = {Quantum Circuit Design: A Reinforcement Learning Challenge},
  year      = {2024},
  isbn      = {9798400704864},
  publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
  address   = {Richland, SC},
  abstract  = {To assess the prospects of using reinforcement learning (RL) for selecting and parameterizing quantum gates to build viable circuit architectures, we introduce the quantum circuit designer (QCD). By considering quantum control a decision-making problem, we strive to profit from advanced RL exploration mechanisms to overcome the need for granular specification and hand-crafted architectures. To evaluate current state-of-the-art RL algorithms, we define generic objectives that arise from quantum architecture search and circuit optimization. Those evaluation results reveal challenges inherent to learning optimal quantum control.},
  booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  pages     = {2123–2125},
  numpages  = {3},
  keywords  = {architecture search, circuit optimization, quantum computing, reinforcement learning},
  location  = {Auckland, New Zealand},
  series    = {AAMAS '24}
}

@conference{Koelle2024Aquarium,
  author       = {Michael Kölle and Yannick Erpelding and Fabian Ritz and Thomy Phan and Steffen Illium and Claudia Linnhoff-Popien},
  title        = {Aquarium: A Comprehensive Framework for Exploring Predator-Prey Dynamics Through Multi-Agent Reinforcement Learning Algorithms},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {59-70},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012382300003636},
  isbn         = {978-989-758-680-4}
}

@conference{Koelle2024MultiAgent,
  author       = {Michael Kölle and Felix Topp and Thomy Phan and Philipp Altmann and Jonas Nüßlein and Claudia Linnhoff-Popien},
  title        = {Multi-Agent Quantum Reinforcement Learning Using Evolutionary Optimization},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {71-82},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012382800003636},
  isbn         = {978-989-758-680-4}
}

@conference{Koelle2024Reinforcement,
  author       = {Michael Kölle and Tom Schubert and Philipp Altmann and Maximilian Zorn and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {A Reinforcement Learning Environment for Directed Quantum Circuit Synthesis},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {83-94},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012383200003636},
  isbn         = {978-989-758-680-4}
}

@conference{Stein2024Improving,
  author       = {Jonas Stein and Navid Roshani and Maximilian Zorn and Philipp Altmann and Michael Kölle and Claudia Linnhoff-Popien},
  title        = {Improving Parameter Training for VQEs by Sequential Hamiltonian Assembly},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {99-109},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012312500003636},
  isbn         = {978-989-758-680-4}
}

@conference{Koelle2024QuantumAdvantage,
  author       = {Michael Kölle and Mohamad Hgog and Fabian Ritz and Philipp Altmann and Maximilian Zorn and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {Quantum Advantage Actor-Critic for Reinforcement Learning},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {297-304},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012383900003636},
  isbn         = {978-989-758-680-4}
}

@conference{Mueller2024ClusterComm,
  author       = {Robert Müller and Hasan Turalic and Thomy Phan and Michael Kölle and Jonas Nüßlein and Claudia Linnhoff-Popien},
  title        = {ClusterComm: Discrete Communication in Decentralized MARL Using Internal Representation Clustering},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 1: ICAART},
  year         = {2024},
  pages        = {305-312},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012384300003636},
  isbn         = {978-989-758-680-4}
}

@conference{Koelle2024Towards,
  author       = {Michael Kölle and Afrae Ahouzi and Pascal Debus and Robert Müller and Daniëlle Schuman and Claudia Linnhoff-Popien},
  title        = {Towards Efficient Quantum Anomaly Detection: One-Class SVMs Using Variable Subsampling and Randomized Measurements},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 2: ICAART},
  year         = {2024},
  pages        = {324-335},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012381200003636},
  isbn         = {978-989-758-680-4}
}

@conference{Stein2024Benchmarking,
  author       = {Jonas Stein and Michael Poppel and Philip Adamczyk and Ramona Fabry and Zixin Wu and Michael Kölle and Jonas Nüßlein and Daniëlle Schuman and Philipp Altmann and Thomas Ehmer and Vijay Narasimhan and Claudia Linnhoff-Popien},
  title        = {Benchmarking Quantum Surrogate Models on Scarce and Noisy Data},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {352-359},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012348900003636},
  isbn         = {978-989-758-680-4}
}

@conference{Koelle2024Disentangling,
  author       = {Michael Kölle and Jonas Maurer and Philipp Altmann and Leo Sünkel and Jonas Stein and Claudia Linnhoff-Popien},
  title        = {Disentangling Quantum and Classical Contributions in Hybrid Quantum Machine Learning Architectures},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {649-656},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012381600003636},
  isbn         = {978-989-758-680-4}
}

@conference{Suenkel2024Quantum,
  author       = {Leo Sünkel and Philipp Altmann and Michael Kölle and Thomas Gabor},
  title        = {Quantum Federated Learning for Image Classification},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {936-942},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012421200003636},
  isbn         = {978-989-758-680-4}
}

@conference{Stein2024Introducing,
  author       = {Jonas Stein and Tobias Rohe and Francesco Nappi and Julian Hager and David Bucher and Maximilian Zorn and Michael Kölle and Claudia Linnhoff-Popien},
  title        = {Introducing Reduced-Width QNNs, an AI-Inspired Ansatz Design Pattern},
  booktitle    = {Proceedings of the 16th International Conference on Agents and Artificial Intelligence - Volume 3: ICAART},
  year         = {2024},
  pages        = {1127-1134},
  publisher    = {SciTePress},
  organization = {INSTICC},
  doi          = {10.5220/0012449800003636},
  isbn         = {978-989-758-680-4}
}

@inproceedings{Suenkel2024Towards,
  author    = {"S\"{u}nkel, Leo
               and K\"{o}lle, Michael
               and Rohe, Tobias
               and Gabor, Thomas"},
  editor    = {Steffen, Bernhard},
  title     = {Towards Federated Learning on the Quantum Internet},
  booktitle = {Computational Science – ICCS 2024: 24th International Conference, Malaga, Spain, July 2–4, 2024, Proceedings, Part VI},
  year      = {2024},
  isbn      = {978-3-031-63777-3},
  publisher = {Springer-Verlag},
  address   = {Berlin, Heidelberg},
  url       = {https://doi.org/10.1007/978-3-031-63778-0_24},
  doi       = {10.1007/978-3-031-63778-0_24},
  abstract  = {While the majority of focus in quantum computing has so far been on monolithic quantum systems, quantum communication networks and the quantum internet in particular are increasingly receiving attention from researchers and industry alike. The quantum internet may allow a plethora of applications such as distributed or blind quantum computing, though research still is at an early stage, both for its physical implementation as well as algorithms; thus suitable applications are an open research question. We evaluate a potential application for the quantum internet, namely quantum federated learning. We run experiments under different settings in various scenarios (e.g. network constraints) using several datasets from different domains and show that (1) quantum federated learning is a valid alternative for regular training and (2) network topology and nature of training are crucial considerations as they may drastically influence the models performance. The results indicate that more comprehensive research is required to optimally deploy quantum federated learning on a potential quantum internet.},
  pages     = {330–344},
  numpages  = {15},
  keywords  = {Quantum Federated Learning, Quantum Internet, Quantum Machine Learning, Quantum Communication Networks},
  location  = {Malaga, Spain}
}

@inproceedings{Koelle2024QuantumDenoising,
  author    = { Kolle, Michael and Stenzel, Gerhard and Stein, Jonas and Zielinski, Sebastian and Ommer, Bjorn and Linnhoff-Popien, Claudia },
  booktitle = { 2024 IEEE International Conference on Quantum Software (QSW) },
  title     = { Quantum Denoising Diffusion Models },
  year      = {2024},
  volume    = {},
  issn      = {},
  pages     = {88-98},
  abstract  = { In recent years, machine learning models like DALL-E, Craiyon, and Stable Diffusion have gained significant attention for their ability to generate high-resolution images from concise descriptions. Concurrently, quantum computing is showing promising advances, especially with quantum machine learning which capitalizes on quantum mechanics to meet the increasing computational requirements of traditional machine learning algorithms. This paper explores the integration of quantum machine learning and variational quantum circuits to augment the efficacy of diffusion-based image generation models. Specifically, we address two challenges of classical diffusion models: their low sampling speed and the extensive parameter requirements. We introduce two quantum diffusion models and benchmark their capabilities against their classical counterparts using MNIST digits, Fashion MNIST, and CIFAR-10. Our models surpass the classical models with similar parameter counts in terms of performance metrics FID, SSIM, and PSNR. Moreover, we introduce a consistency model unitary single sampling architecture that combines the diffusion procedure into a single step, enabling a fast one-step image generation. },
  keywords  = {Measurement;Image synthesis;Computational modeling;Noise reduction;Computer architecture;Benchmark testing;Diffusion models},
  doi       = {10.1109/QSW62656.2024.00023},
  url       = {https://doi.ieeecomputersociety.org/10.1109/QSW62656.2024.00023},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = Jul
}

@inproceedings{Koelle2024Study,
  author    = { Kolle, Michael and Witter, Timo and Rohe, Tobias and Stenzel, Gerhard and Altmann, Philipp and Gabor, Thomas },
  booktitle = { 2024 IEEE International Conference on Quantum Software (QSW) },
  title     = { A Study on Optimization Techniques for Variational Quantum Circuits in Reinforcement Learning },
  year      = {2024},
  volume    = {},
  issn      = {},
  pages     = {157-167},
  abstract  = { Quantum Computing aims to streamline machine learning, making it more effective with fewer trainable parameters. This reduction of parameters can speed up the learning process and reduce the use of computational resources. However, in the current phase of quantum computing development, known as the noisy intermediate-scale quantum era (NISQ), learning is difficult due to a limited number of qubits and widespread quantum noise. To overcome these challenges, researchers are focusing on variational quantum circuits (VQCs). VQCs are hybrid algorithms that merge a quantum circuit, which can be adjusted through parameters, with traditional classical optimization techniques. These circuits require only few qubits for effective learning. Recent studies have presented new ways of applying VQCs to reinforcement learning, showing promising results that warrant further exploration. This study investigates the effects of various techniques — data re-uploading, input scaling, output scaling — and introduces exponential learning rate decay in the quantum proximal policy optimization algorithm’s actor-VQC. We assess these methods in the popular Frozen Lake and Cart Pole environments. Our focus is on their ability to reduce the number of parameters in the VQC without losing effectiveness. Our findings indicate that data re-uploading and an exponential learning rate decay significantly enhance hyperparameter stability and overall performance. While input scaling does not improve parameter efficiency, output scaling effectively manages greediness, leading to increased learning speed and robustness. },
  keywords  = {Qubit;Noise;Reinforcement learning;Software;Robustness;Circuit stability;Time factors},
  doi       = {10.1109/QSW62656.2024.00031},
  url       = {https://doi.ieeecomputersociety.org/10.1109/QSW62656.2024.00031},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = Jul
}

@inproceedings{Stenzel2025SEGym,
  author    = {"Stenzel, Gerhard
               and Schmid, Kyrill
               and K{\"o}lle, Michael
               and Altmann, Philipp
               and Lingsch-Rosenfeld, Marian
               and Zorn, Maximilian
               and B{\"u}cher, Tim
               and Gabor, Thomas
               and Wirsing, Martin
               and Belzner, Lenz"},
  editor    = {Steffen, Bernhard},
  title     = {SEGym: Optimizing Large Language Model Assisted Software Engineering Agents with Reinforcement Learning},
  booktitle = {Bridging the Gap Between AI and Reality},
  year      = {2025},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {107--124},
  abstract  = {Current software development agents based on large language models (LLMs) are often defined using heuristic methods, which can limit their flexibility and effectiveness. Moreover, the entry barriers for new researchers in this field are high, largely due to the complex infrastructure required to develop and optimize these agents. This paper proposes a new approach: modeling software development agents over LLMs as a partially observable Markov decision process (POMDP) to enable data-driven optimization. To support this approach, we introduce SEGym, a framework based on the Gym interface for reinforcement learning agents. SEGym simplifies the setup of optimization experiments for software development agents within the POMDP framework, making it more accessible for researchers to engage in this field.},
  isbn      = {978-3-031-75434-0}
}

# Unpublished

@article{Koelle2022Decentralized,
  author     = {Michael Kölle and
                Lennart Rietdorf and
                Kyrill Schmid},
  title      = {Decentralized scheduling through an adaptive, trading-based multi-agent
                system},
  journal    = {CoRR},
  volume     = {abs/2207.11172},
  year       = {2022},
  url        = {https://doi.org/10.48550/arXiv.2207.11172},
  doi        = {10.48550/ARXIV.2207.11172},
  eprinttype = {arXiv},
  eprint     = {2207.11172},
  note       = {Presented at the 4th International Workshop on Agent-Based Modelling 
                of Human Behaviour (ABMHuB'22)},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2207-11172.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}